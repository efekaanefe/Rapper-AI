{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNut/E/ZzO3UVhQKfrBhRtW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efekaanefe/Rapper-AI/blob/main/rapper_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NFXpPuOyTlLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('eminem-lyrics.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcSvEK1yT_0t",
        "outputId": "c67793f2-f646-4582-d09e-8011584ededb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102390"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41iePTrABbgS",
        "outputId": "b069104a-a06c-4d12-e0f3-b9808633736b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 14734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a character-level vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "char_size = len(chars)\n",
        "\n",
        "words = text.split()\n",
        "unique_words = sorted(list(set(words)))\n",
        "vocab_size = len(unique_words)\n",
        "\n",
        "print(f'Unique characters size: {char_size}')\n",
        "print(f'Unique words/vocabulary size: {vocab_size}')\n",
        "\n",
        "\n",
        "# Create mappings from characters to indices and vice versa\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "encoded_text = np.array([char_to_idx[char] for char in text])\n",
        "\n",
        "seq_length = 100 # Sequence length\n",
        "num_samples = len(encoded_text) // seq_length\n",
        "\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    start_idx = i * seq_length\n",
        "    end_idx = start_idx + seq_length\n",
        "    input_sequences.append(encoded_text[start_idx:end_idx])\n",
        "    target_sequences.append(encoded_text[start_idx + 1:end_idx + 1])\n",
        "\n",
        "input_sequences = torch.tensor(np.array(input_sequences), dtype=torch.long)\n",
        "target_sequences = torch.tensor(np.array(target_sequences), dtype=torch.long)\n",
        "\n",
        "print(input_sequences.shape, target_sequences.shape, encoded_text.shape)\n"
      ],
      "metadata": {
        "id": "j4WJRwvzVJWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5681550-ca50-4abb-ec53-27d2338ee6e1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size (unique char size actuall!!!): 95\n",
            "torch.Size([5225, 100]) torch.Size([5225, 100]) (522527,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"1st input sequence: \\n{input_sequences[0]}\", end=\"\\n\\n\")\n",
        "print(\"Input sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in input_sequences[0]]), end=\"\\n\\n\")\n",
        "print(\"Target sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in target_sequences[0]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7orJOGR3-YNA",
        "outputId": "86b89a5f-5dd6-424c-8955-2de8997f7301"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st input sequence: \n",
            "tensor([44, 66,  1, 83, 63, 59, 66, 13,  1, 78, 66, 67, 77,  1, 67, 77,  1, 34,\n",
            "        71, 67, 72, 63, 71,  1, 60, 59, 60, 83, 13,  1, 60, 59, 61, 69,  1, 79,\n",
            "        74,  1, 67, 72,  1, 78, 66, 59, 78,  1, 71, 73, 78, 66, 63, 76, 64, 79,\n",
            "        61, 69, 67, 72, 65,  1, 59, 77, 77,  0, 44, 72, 63,  1, 78, 67, 71, 63,\n",
            "         1, 64, 73, 76,  1, 83, 73, 79, 76,  1, 71, 73, 78, 66, 63, 76,  1, 64,\n",
            "        79, 61, 69, 67, 72, 65,  1, 71, 67, 72])\n",
            "\n",
            "Input sequence as words:\n",
            "Oh yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking min\n",
            "\n",
            "Target sequence as words:\n",
            "h yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(out.reshape(out.size(0) * out.size(1), out.size(2)))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        return (weight.new_zeros(num_layers, batch_size, hidden_size),\n",
        "                weight.new_zeros(num_layers, batch_size, hidden_size))\n"
      ],
      "metadata": {
        "id": "uj_FPIfI-w5I"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9vL_n8SnAXJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}