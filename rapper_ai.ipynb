{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrVliCSvydFZI4S6xDMqQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efekaanefe/Rapper-AI/blob/main/rapper_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NFXpPuOyTlLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('eminem-lyrics.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcSvEK1yT_0t",
        "outputId": "c67793f2-f646-4582-d09e-8011584ededb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102390"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word level inputs and targets"
      ],
      "metadata": {
        "id": "mJmUpIdEC3m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "unique_words = sorted(list(set(words)))\n",
        "vocab_size = len(unique_words)\n",
        "print(f'Unique words/vocabulary size: {vocab_size}')\n",
        "\n",
        "# Create mappings from words to indices and vice versa\n",
        "word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n",
        "idx_to_word = {idx: word for idx, word in enumerate(unique_words)}\n",
        "\n",
        "# Encode the text using word-level vocabulary\n",
        "encoded_text = np.array([word_to_idx[word] for word in words])\n",
        "\n",
        "seq_length = 10  # Adjust sequence length as needed for words\n",
        "num_samples = len(encoded_text) // seq_length\n",
        "\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "# The fix: Ensure all sequences are of the same length by padding shorter ones\n",
        "for i in range(num_samples):\n",
        "    start_idx = i * seq_length\n",
        "    end_idx = start_idx + seq_length\n",
        "\n",
        "    input_seq = encoded_text[start_idx:end_idx]\n",
        "    target_seq = encoded_text[start_idx + 1:end_idx + 1]\n",
        "\n",
        "    # Pad if the sequence is shorter than seq_length\n",
        "    if len(input_seq) < seq_length:\n",
        "        input_seq = np.pad(input_seq, (0, seq_length - len(input_seq)), 'constant', constant_values=0)  # Pad with zeros\n",
        "    if len(target_seq) < seq_length:\n",
        "        target_seq = np.pad(target_seq, (0, seq_length - len(target_seq)), 'constant', constant_values=0)  # Pad with zeros\n",
        "\n",
        "    input_sequences.append(input_seq)\n",
        "    target_sequences.append(target_seq)\n",
        "\n",
        "input_sequences = torch.tensor(np.array(input_sequences), dtype=torch.long)\n",
        "target_sequences = torch.tensor(np.array(target_sequences), dtype=torch.long)\n",
        "\n",
        "print(input_sequences.shape, target_sequences.shape, encoded_text.shape)\n",
        "\n",
        "print(f\"1st input sequence: \\n{input_sequences[0]}\", end=\"\\n\\n\")\n",
        "print(\"Input sequence as words:\")\n",
        "print(' '.join([idx_to_word[int(i)] for i in input_sequences[0]]), end=\"\\n\\n\")\n",
        "print(\"Target sequence as words:\")\n",
        "print(' '.join([idx_to_word[int(i)] for i in target_sequences[0]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41iePTrABbgS",
        "outputId": "22b0590d-844e-4a42-8bdf-447340abcb5c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words/vocabulary size: 14734\n",
            "torch.Size([10239, 10]) torch.Size([10239, 10]) (102390,)\n",
            "1st input sequence: \n",
            "tensor([ 2823, 14612, 13434,  8898,  1632,  4696,  4703, 13907,  8759, 13351])\n",
            "\n",
            "Input sequence as words:\n",
            "Oh yeah, this is Eminem baby, back up in that\n",
            "\n",
            "Target sequence as words:\n",
            "yeah, this is Eminem baby, back up in that motherfucking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Character level inputs and targets"
      ],
      "metadata": {
        "id": "3i-_s1FtC9rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a character-level vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "char_size = len(chars)\n",
        "print(f'Unique characters size: {char_size}')\n",
        "\n",
        "# Create mappings from characters to indices and vice versa\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "encoded_text = np.array([char_to_idx[char] for char in text])\n",
        "\n",
        "seq_length = 100 # Sequence length\n",
        "num_samples = len(encoded_text) // seq_length\n",
        "\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    start_idx = i * seq_length\n",
        "    end_idx = start_idx + seq_length\n",
        "    input_sequences.append(encoded_text[start_idx:end_idx])\n",
        "    target_sequences.append(encoded_text[start_idx + 1:end_idx + 1])\n",
        "\n",
        "input_sequences = torch.tensor(np.array(input_sequences), dtype=torch.long)\n",
        "target_sequences = torch.tensor(np.array(target_sequences), dtype=torch.long)\n",
        "\n",
        "print(input_sequences.shape, target_sequences.shape, encoded_text.shape)\n",
        "\n",
        "print(f\"1st input sequence: \\n{input_sequences[0]}\", end=\"\\n\\n\")\n",
        "print(\"Input sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in input_sequences[0]]), end=\"\\n\\n\")\n",
        "print(\"Target sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in target_sequences[0]]))\n"
      ],
      "metadata": {
        "id": "j4WJRwvzVJWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a636e970-9f8d-413f-a257-d25cfca20d08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters size: 95\n",
            "torch.Size([5225, 100]) torch.Size([5225, 100]) (522527,)\n",
            "1st input sequence: \n",
            "tensor([44, 66,  1, 83, 63, 59, 66, 13,  1, 78, 66, 67, 77,  1, 67, 77,  1, 34,\n",
            "        71, 67, 72, 63, 71,  1, 60, 59, 60, 83, 13,  1, 60, 59, 61, 69,  1, 79,\n",
            "        74,  1, 67, 72,  1, 78, 66, 59, 78,  1, 71, 73, 78, 66, 63, 76, 64, 79,\n",
            "        61, 69, 67, 72, 65,  1, 59, 77, 77,  0, 44, 72, 63,  1, 78, 67, 71, 63,\n",
            "         1, 64, 73, 76,  1, 83, 73, 79, 76,  1, 71, 73, 78, 66, 63, 76,  1, 64,\n",
            "        79, 61, 69, 67, 72, 65,  1, 71, 67, 72])\n",
            "\n",
            "Input sequence as words:\n",
            "Oh yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking min\n",
            "\n",
            "Target sequence as words:\n",
            "h yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "BB9w401aDoxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(out.reshape(out.size(0) * out.size(1), out.size(2)))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        return (weight.new_zeros(num_layers, batch_size, hidden_size),\n",
        "                weight.new_zeros(num_layers, batch_size, hidden_size))\n"
      ],
      "metadata": {
        "id": "uj_FPIfI-w5I"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "vW6H2DzhDqxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embed_size = 512\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "\n",
        "model = LSTMModel(vocab_size, embed_size, hidden_size, num_layers)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "9vL_n8SnAXJU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, input_sequences.size(0) - batch_size, batch_size):\n",
        "        inputs = input_sequences[i:i+batch_size]\n",
        "        targets = target_sequences[i:i+batch_size]\n",
        "\n",
        "        hidden = tuple([h.detach() for h in hidden])\n",
        "\n",
        "        # Forward\n",
        "        outputs, hidden = model(inputs, hidden)\n",
        "        loss = criterion(outputs, targets.view(-1))\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / (input_sequences.size(0) // batch_size)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULnoqpqtEK5T",
        "outputId": "b30be568-1be7-4050-ee4b-90a78f3937fe"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Loss: 7.6352\n"
          ]
        }
      ]
    }
  ]
}