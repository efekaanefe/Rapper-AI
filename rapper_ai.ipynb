{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1aQHs+zhTsABstBuT+g3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efekaanefe/Rapper-AI/blob/main/rapper_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NFXpPuOyTlLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('eminem-lyrics.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "words = text.split()\n",
        "\n",
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcSvEK1yT_0t",
        "outputId": "c67793f2-f646-4582-d09e-8011584ededb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102390"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a character-level vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size}')\n",
        "\n",
        "# Create mappings from characters to indices and vice versa\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
        "\n",
        "encoded_text = np.array([char_to_idx[char] for char in text])\n",
        "\n",
        "seq_length = 100 # Sequence length\n",
        "num_samples = len(encoded_text) // seq_length\n",
        "\n",
        "input_sequences = []\n",
        "target_sequences = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    start_idx = i * seq_length\n",
        "    end_idx = start_idx + seq_length\n",
        "    input_sequences.append(encoded_text[start_idx:end_idx])\n",
        "    target_sequences.append(encoded_text[start_idx + 1:end_idx + 1])\n",
        "\n",
        "input_sequences = torch.tensor(np.array(input_sequences), dtype=torch.long)\n",
        "target_sequences = torch.tensor(np.array(target_sequences), dtype=torch.long)\n",
        "\n",
        "print(input_sequences.shape, target_sequences.shape, encoded_text.shape)\n"
      ],
      "metadata": {
        "id": "j4WJRwvzVJWs",
        "outputId": "b37491f4-358e-4608-c778-9d90381f62b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 95\n",
            "torch.Size([5225, 100]) torch.Size([5225, 100]) (522527,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"1st input sequence \\n{input_sequences[0]}\", end=\"\\n\\n\")\n",
        "print(\"Input sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in input_sequences[0]]), end=\"\\n\\n\")\n",
        "print(\"Target sequence as words:\")\n",
        "print(''.join([idx_to_char[int(i)] for i in target_sequences[0]]))\n"
      ],
      "metadata": {
        "id": "7orJOGR3-YNA",
        "outputId": "2740246e-513c-4100-e8dc-a32f499732d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st input sequence \n",
            "tensor([44, 66,  1, 83, 63, 59, 66, 13,  1, 78, 66, 67, 77,  1, 67, 77,  1, 34,\n",
            "        71, 67, 72, 63, 71,  1, 60, 59, 60, 83, 13,  1, 60, 59, 61, 69,  1, 79,\n",
            "        74,  1, 67, 72,  1, 78, 66, 59, 78,  1, 71, 73, 78, 66, 63, 76, 64, 79,\n",
            "        61, 69, 67, 72, 65,  1, 59, 77, 77,  0, 44, 72, 63,  1, 78, 67, 71, 63,\n",
            "         1, 64, 73, 76,  1, 83, 73, 79, 76,  1, 71, 73, 78, 66, 63, 76,  1, 64,\n",
            "        79, 61, 69, 67, 72, 65,  1, 71, 67, 72])\n",
            "\n",
            "Input sequence as words:\n",
            "Oh yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking min\n",
            "\n",
            "Target sequence as words:\n",
            "h yeah, this is Eminem baby, back up in that motherfucking ass\n",
            "One time for your mother fucking mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uj_FPIfI-w5I"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}